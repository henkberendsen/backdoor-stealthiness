\renewcommand{\arraystretch}{0.9}
\begin{table}
    \centering
    \setlength\tabcolsep{2pt}
    \caption{Performance of ResNet18 models on four datasets. The benign accuracy (BA) is shown for both benign and backdoored models. The poisoning rate (PR) is specified for backdoored models, and their attack success rate (ASR) is also reported. For the backdoored models, ASR scores below 60\% are highlighted in red.
    *The poisoning rates vary per dataset.}
    \label{tab:attack-performance-4datasets}
    \begin{tabular}{lccccccccc}
    \toprule
        \multirow{2}{*}{Attack} & \multirow{2}{*}{PR (\%)} & \multicolumn{2}{c}{CIFAR-10} & \multicolumn{2}{c}{CIFAR-100} & \multicolumn{2}{c}{Tiny} & \multicolumn{2}{c}{Imagenette}\\
         \cmidrule(lr){3-4}
         \cmidrule(lr){5-6}
         \cmidrule(lr){7-8}
         \cmidrule(lr){9-10}
         ~ & ~ & BA & ASR & BA & ASR & BA & ASR & BA & ASR \\
         \midrule
         Benign & - & 94.7 & - & 73.3 & - & 59.21 & - & 87.7 & -\\
         \cmidrule(lr){2-10}
         \multirow{2}{*}{BadNets} & 5 & 94.5 & 100 & 72.9 & 100 & 58.37 & 99.97 & 88.3 & 100\\
         ~ & 0.3 & 94.7 & 100 & 73.5 & 99.8 & 59.12 & 94.04 & 88.1 & 86.7\\
         \cmidrule(lr){2-10}
         \multirow{2}{*}{Blend} & 5 & 94.3 & 99.8 & 72.4 & 99.7 & 58.24 & 99.38 & 88.6 & 98.9\\
         ~ & 0.3 & 94.8 & 94.8 & 73.6 & 88.6 & 58.74 & 84.22 & 88.6 & 73.5\\
         \cmidrule(lr){2-10}
         \multirow{2}{*}{WaNet} & 5 & 93.4 & 98.5 & 66.8 & 99.8 & 57.88 & 99.93 & 86.6 & 97.2\\
         ~ & \scriptsize{2/0.3/0.3/0.3$^*$} & 93.5 & 95.3 & 66.6 & 91.7 & 58.64 & 87.94 & 79.1 & 61.0\\
         \cmidrule(lr){2-10}
         \multirow{2}{*}{BppAttack} & 5 & 94.4 & 99.8 & 73.0 & 99.9 & 59.36 & 98.43 & 88.9 & 73.6 \\
         ~ & \scriptsize{2/0.3/0.3/0.3$^*$} & 94.6 & 69.5 & 73.0 & 88.0 & 58.56 & \textcolor{red}{4.72} & 88.3 & \textcolor{red}{1.02} \\
         \cmidrule(lr){2-10}
         \multirow{2}{*}{Adap-Patch} & 5 & 93.9 & \textcolor{red}{30.1} & 70.9 & 66.7 & 56.97 & \textcolor{red}{41.62} & 87.6 & \textcolor{red}{20.2}\\
         ~ & 0.3 & 94.5 & 92.2 & 72.7 & \textcolor{red}{2.98} & 58.39 & \textcolor{red}{0.26} & 88.1 & \textcolor{red}{0.565}\\
         \cmidrule(lr){2-10}
         \multirow{2}{*}{Adap-Blend} & 5 & 94.0 & \textcolor{red}{53.9} & 71.8 & 90.6 & 57.59 & 96.36 & 87.6 & 94.9\\
         ~ & 0.3 & 94.6 & 87.9 & 72.6 & 82.0 & 58.9 & 81.58 & 88.5 & \textcolor{red}{54.4} \\
         \cmidrule(lr){2-10}
         \multirow{2}{*}{DFST} & 5 & 95.0 & 100 & 73.6 & 100 & 59.23 & 100 & 88.7 & 99.5\\
         ~ & 0.3 & 94.8 & 100 & 73.6 & 99.9 & 58.79 & 99.84 & 88.4 & 99.7\\
         \cmidrule(lr){2-10}
         \multirow{2}{*}{Narcissus} & \scriptsize{5/0.7/0.4/5$^*$} & 94.4 & 100 & 73.0 & 70.9 & 59.04 & 98.82 & 87.8 & 86.1\\
         ~ & 0.3 & 94.7 & 98.9 & 72.8 & \textcolor{red}{33.1} & 58.97 & 98.97 & 88.7 & \textcolor{red}{13.6} \\
         \cmidrule(lr){2-10}
         \multirow{2}{*}{Grond} & \scriptsize{5/0.7/0.4/5$^*$} & 94.7 & 92.9 & 74.7 & \textcolor{red}{58.7} & 59.02 & 76.32 & 87.0 & 60.2\\
         ~ & 0.3 & 94.5 & 76.6 & 74.7 & \textcolor{red}{43.5} & 58.68 & 74.29 & 87.4 & \textcolor{red}{1.81}\\
         \cmidrule(lr){2-10}
         DFBA & - & 94.3 & 100 & 72.0 & 100 & 55.95 & 100 & 87.6 & 100\\
         \bottomrule
    \end{tabular}
\end{table}% four datasets in one, input space stealthiness



\begin{table*}[ht]
    \centering
    \caption{Input-space stealthiness evaluation on four datasets.}
    \setlength\tabcolsep{3pt}
    \renewcommand{\arraystretch}{0.9}
    \label{tab:input-stealthiness-all}
    \begin{tabular}{llcccccccccc}
    \toprule
    \multirow{2}{*}{Dataset} & Metric & $l_1 \downarrow$ & $l_2 \downarrow$ & $l_\infty \downarrow$ & MSE $\downarrow$& PSNR $\uparrow$& SSIM $\uparrow$& LPIPS $\downarrow$& IS $\downarrow$& pHash $\uparrow$& SAM $\downarrow$\\
    ~ & Ideal value & 0 & 0 & 0 & 0 & $\infty$ & 1 & 0 & 0 & 100 & 0 \\
    \midrule
    \multirow{13}{*}{CIFAR-10} & BadNets & \best{13.2} & 2.84 & 0.811 & 2.64e-3 & 25.8 & 0.956 & 4.41e-3 & 0.170 & 95.2 & \best{1.44e-3} \\
    ~ & Blend & 230 & 4.92 & 0.191 & 8.01e-3 & 21.0 & 0.784 & 0.0483 & 2.37 & 89.8 & 0.0830 \\
    ~ & WaNet & 46.5 & 1.42 & 0.173 & 7.17e-4 & 31.5 & 0.978 & 4.32e-3 & 0.270 & 96.1 & 0.0119 \\
    ~ & BppAttack & 24.6 & \best{0.525} & \best{0.0196} & \best{8.97e-5} & \best{40.5} & \best{0.992} & \best{1.94e-4} & \best{0.150} & \best{99.2} & 0.0239 \\
    ~ & Adap-Patch (train) & 22.5 & 2.06 & 0.315 & 1.53e-3 & 28.7 & 0.972 & 4.78e-3 & 0.296 & 95.2 & 9.43e-3 \\
    ~ & Adap-Patch (test) & 74.1 & 6.77 & \worst{0.913} & 0.0151 & 18.2 & 0.956 & 0.0120 & 0.724 & 87.7 & 8.94e-3 \\
    ~ & Adap-Blend (train) & 87.0 & 2.63 & 0.142 & 2.30e-3 & 26.4 & 0.903 & 0.0136 & 0.823 & 92.4 & 0.0336 \\
    ~ & Adap-Blend (test) & 232 & 4.97 & 0.192 & 8.15e-3 & 20.9 & 0.783 & 0.0485 & 2.37 & 89.8 & 0.0831 \\
    ~ & DFST & 487 & \worst{10.8} & 0.489 & \worst{0.0400} & \worst{14.0} & 0.719 & 0.165 & 2.22 & 88.6 & 0.316 \\
    ~ & Narcissus (train) & 188 & 3.43 & 0.0627 & 3.83e-3 & 24.2 & 0.818 & 0.0545 & 1.44 & 91.8 & 0.101 \\
    ~ & Narcissus (test) & \worst{542} & 9.98 & 0.188 & 0.0325 & 14.9 & \worst{0.532} & \worst{0.184} & \worst{3.68} & \worst{82.2} & \worst{0.331} \\
    ~ & Grond & 87.6 & 1.62 & 0.0348 & 8.59e-4 & 30.7 & 0.934 & 2.92e-3 & 0.918 & 97.9 & 0.0833 \\
    ~ & DFBA & 13.5 & 2.99 & 0.844 & 2.94e-3 & 25.3 & \best{0.992} & 1.66e-3 & 0.159 & 97.4 & 2.83e-3 \\
    \midrule
    \multirow{13}{*}{CIFAR-100} & BadNets & \best{13.3} & 2.91 & 0.839 & 2.79e-3 & 25.6 & 0.955 & 5.39e-3 & 0.182 & 94.1 & \best{1.66e-3} \\
    ~ & Blend & 232 & 4.98 & 0.191 & 8.23e-3 & 20.8 & 0.765 & 0.0512 & \worst{2.25} & 89.0 & 0.0876 \\
    ~ & WaNet & 55.3 & 1.64 & 0.177 & 9.55e-4 & 30.2 & 0.968 & 6.72e-3 & 0.308 & 95.2 & 0.0154 \\
    ~ & BppAttack & 24.3 & \best{0.520} & \best{0.0196} & \best{8.83e-5} & \best{40.5} & 0.991 & \best{2.06e-4} & \best{0.138} & \best{99.1} & 0.0235 \\
    ~ & Adap-Patch (train) & 22.7 & 2.09 & 0.320 & 1.59e-3 & 28.5 & 0.971 & 4.78e-3 & 0.297 & 94.4 & 9.51e-3 \\
    ~ & Adap-Patch (test) & 74.5 & 6.96 & \worst{0.928} & 0.0159 & 18.0 & 0.956 & 0.0135 & 0.805 & 86.2 & 9.73e-3 \\
    ~ & Adap-Blend (train) & 87.9 & 2.66 & 0.142 & 2.36e-3 & 26.3 & 0.894 & 0.0144 & 0.796 & 91.5 & 0.0356 \\
    ~ & Adap-Blend (test) & 234 & 5.02 & 0.192 & 8.36e-3 & 20.8 & 0.764 & 0.0513 & \worst{2.25} & 89.0 & 0.0877 \\
    ~ & DFST & 509 & \worst{11.3} & 0.495 & \worst{0.0444} & \worst{13.5} & 0.708 & \worst{0.169} & 2.16 & 87.7 & 0.312 \\
    ~ & Narcissus (train) & 174 & 3.27 & 0.0627 & 3.50e-3 & 24.6 & 0.884 & 0.0147 & 0.622 & 94.3 & 0.126 \\
    ~ & Narcissus (test) & \worst{528} & 9.82 & 0.188 & 0.0315 & 15.0 & \worst{0.630} & 0.166 & 2.22 & \worst{84.6} & \worst{0.347} \\
    ~ & Grond & 86.9 & 1.61 & 0.0347 & 8.50e-4 & 30.7 & 0.929 & 4.97e-3 & 0.876 & 97.9 & 0.0720 \\
    ~ & DFBA & 13.5 & 3.02 & 0.843 & 3.04e-3 & 25.2 & \best{0.993} & 7.74e-3 & 0.146 & 95.9 & 4.18e-3 \\
    \midrule
    \multirow{13}{*}{Tiny-ImageNet} & BadNets & 58.36 & 4.99 & 0.73 & 2.23e-3 & 26.53 & 0.96 & 4.15e-2 & 0.11 & 91.79 & 3.47e-3\\
    ~ & Blend & 921.81 & 9.95 & 0.2 & 8.22e-3 & 20.85 & 0.81 & 0.11 & 1.11 & 89.44 & 0.11\\
    ~ & WaNet & 317.02 & 4.94 & 0.35 & 2.20e-3 & 26.58 & 0.93 & 4.03e-2 & 0.27 & 97.35 & 2.60e-2\\
    ~ & BppAttack & 96.26 & \best{1.04} & \best{1.96e-2} & \best{8.76e-5} & \best{40.57} & 0.99 & \best{8.75e-4} & 9.75e-2 & 99.42 & 3.14e-2\\
    ~ & Adap-Patch (train) & 23.54 & 2.17 & 0.33 & 4.22e-4 & 34.22 & 0.99 & 2.56e-3 & 5.07e-2 & 96.93 & 2.93e-3\\
    ~ & Adap-Patch (test) & 75.68 & 7.06 & \worst{0.96} & 4.11e-3 & 23.87 & 0.99 & 8.12e-3 & 0.17 & 92.05 & 3.05e-3\\
    ~ & Adap-Blend (train) & 358.75 & 5.45 & 0.15 & 2.47e-3 & 26.07 & 0.91 & 4.19e-2 & 0.49 & 91.8 & 4.67e-2\\
    ~ & Adap-Blend (test) & 955.04 & 10.28 & 0.2 & 8.77e-3 & 20.58 & 0.79 & 0.13 & 1.42 & 89.21 & 0.11\\
    ~ & DFST & 1.97e+3 & 22.16 & 0.53 & 4.18e-2 & 13.83 & 0.68 & 0.32 & 1.72 & 87.87 & 0.31\\
    ~ & Narcissus (train) & 1.23e+3 & 12.1 & 0.2 & 1.19e-2 & 19.23 & 0.65 & 0.22 & 1.55 & 85.56 & 0.26\\
    ~ & Narcissus (test) & \worst{3.29e+3} & \worst{33.31} & 0.59 & \worst{9.05e-2} & \worst{10.43} & \worst{0.36} & \worst{0.56} & \worst{4.73} & \worst{70.98} & \worst{0.5}\\
    ~ & Grond & 671.95 & 6.31 & 6.67e-2 & 3.25e-3 & 24.89 & 0.8 & 0.16 & 1.68 & 96.83 & 0.17\\
    ~ & DFBA & \best{13.34} & 3.01 & 0.87 & 7.49e-4 & 31.26 & \best{0.99} & 2.09e-3 & \best{4.42e-2} & \best{99.59} & \best{1.34e-3}\\
    \midrule
    \multirow{13}{*}{Imagenette} & BadNets & 73.3 & 6.94 & 0.879 & 2.54e-3 & 26.0 & 0.981 & 0.0152 & 0.0331 & 97.2 & 1.44e-3 \\
    ~ & Blend & 1.62e-3 & 13.8 & 0.198 & 0.0100 & 20.0 & 0.697 & 0.203 & 3.10 & 89.9 & 0.0968 \\
    ~ & WaNet & 225 & 2.94 & 0.190 & 4.94e-4 & 33.3 & 0.981 & 0.0140 & 0.0775 & 98.0 & 0.0111 \\
    ~ & BppAttack & 151 & \best{1.30} & \best{0.0196} & \best{8.79e-5} & \best{40.6} & 0.983 & \best{1.87e-3} & 0.0990 & 99.4 & 0.0294 \\
    ~ & Adap-Patch (train) & 136 & 5.18 & 0.342 & 1.54e-3 & 28.2 & 0.967 & 0.0229 & 0.175 & 94.7 & 0.0101 \\
    ~ & Adap-Patch (test) & 424 & 16.7 & \worst{0.960} & 0.0147 & 18.4 & 0.955 & 0.0540 & 0.238 & 86.9 & 9.00e-3 \\
    ~ & Adap-Blend (train) & 615 & 7.35 & 0.147 & 2.87e-3 & 25.4 & 0.865 & 0.0769 & 0.844 & 92.0 & 0.0413 \\
    ~ & Adap-Blend (test) & 1.64e3 & 13.9 & 0.198 & 0.0102 & 19.9 & 0.697 & 0.203 & 3.09 & 89.9 & 0.0969 \\
    ~ & DFST & 3.22e3 & \worst{28.9} & 0.532 & \worst{0.0456} & \worst{13.5} & 0.692 & 0.335 & 1.52 & 88.1 & \worst{0.334} \\
    ~ & Narcissus (train) & 1.17e3 & 8.55 & 0.0627 & 3.81e-3 & 24.2 & 0.861 & 0.113 & 0.669 & 93.4 & 0.139 \\
    ~ & Narcissus (test) & \worst{3.31e3} & 24.6 & 0.188 & 0.0317 & 15.0 & \worst{0.615} & \worst{0.428} & \worst{3.37} & \worst{82.8} & 0.268 \\
    ~ & Grond & 476 & 3.66 & 0.0352 & 7.00e-4 & 31.6 & 0.882 & 0.0482 & 1.02 & 99.1 & 0.0521 \\
    ~ & DFBA & \best{13.5} & 3.05 & 0.855 & 4.90e-4 & 33.1 & \best{0.999} & 2.07e-3 & \best{0.0312} & \best{99.8} & \best{8.93e-4} \\
    \bottomrule
    \end{tabular}
\end{table*}



\renewcommand{\arraystretch}{0.9}
\begin{table*}[t]
\centering
\setlength\tabcolsep{2pt}
\caption{Feature-space stealthiness of backdoored ResNet18 models trained on four datasets. The metrics used to evaluate each model are the silhouette score (SS), discriminant sliced-Wasserstein distance (DSWD), and Backdoor Mahalanobis Stealthiness (BMS). For each metric and dataset, the \best{best} and \worst{worst} results are highlighted. Results that may be affected by the low ASR of the corresponding models (see Table~\ref{tab:attack-performance-4datasets}) are \underline{underlined}. *The poisoning rates vary per dataset.}
\label{tab:results_feature_resnet18}
\begin{tabular}{l c c c c c c c c c cccccccc}
\toprule
\multirow{2}{*}{Model} & \multirow{2}{*}{PR (\%)} 
& \multicolumn{3}{c}{CIFAR-10} 
& \multicolumn{3}{c}{CIFAR-100} 
& \multicolumn{3}{c}{Tiny-ImageNet} 
& \multicolumn{3}{c}{Imagenette} \\
\cmidrule(lr){3-5} \cmidrule(lr){6-8} \cmidrule(lr){9-11} \cmidrule(lr){12-14}
& & SS$\downarrow$ & DSWD$\downarrow$ & BMS$\downarrow$ &
SS$\downarrow$ & DSWD$\downarrow$ & BMS$\downarrow$ &
SS$\downarrow$ & DSWD$\downarrow$ & BMS$\downarrow$ & 
SS$\downarrow$ & DSWD$\downarrow$ & BMS$\downarrow$\\
\midrule
\multirow{2}{*}{BadNets} 
& 5   & 0.507 & 2.01 & 34.00 & 0.511 & 1.27 & 22.33 & 0.295 & 1.067 & 27.21 & 0.588 & 1.78 & 51.47\\
& 0.3 & 0.355 & 2.54 & 76.61 & 0.462 & 1.29 & 25.62 & 0.463 & 1.145 & 47.64 & 0.260 & 1.49 & 48.40\\
\cmidrule(lr){2-14}
\multirow{2}{*}{Blend} 
& 5   & 0.473 & 2.05 & 38.02 & 0.435 & 1.27 & 21.43 & 0.339 & 1.339 & 23.82 & 0.0216 & 1.60 & 27.40\\
& 0.3 & 0.276 & 2.08 & 48.66 & 0.379 & 1.32 & 30.96 & 0.423 & 1.236 & 46.28 & 0.0975 & 1.27 & 25.45\\
\cmidrule(lr){2-14}
\multirow{2}{*}{WaNet} 
& 5   & 0.382 & 1.83 & 32.71 & 0.492 & 1.21 & \best{15.24} & 0.342 & 1.301 & \best{20.66} & 0.557 & 1.73 & 24.81\\
& 2/0.3/0.3/0.3$^*$ & 0.378 & 1.62 & 18.76 & 0.217 & 0.877 & 22.20 & 0.303 & 0.926 & 38.28 & 0.192 & 0.474 & 15.29\\
\cmidrule(lr){2-14}
\multirow{2}{*}{BppAttack} 
& 5   & 0.500 & 1.91 & 97.43 & 0.527 & 1.37 & 38.44 & 0.433 & 1.36 & 32.69 & 0.607 & 1.34 & \worst{142.88}\\
& 2/0.3/0.3/0.3$^*$ & 0.371 & 0.952 & 16.10 & 0.540 & 1.31 & 36.00 & \underline{0.347} & \best{\underline{0.049}} & 23.06 & \underline{0.227} & \best{\underline{0.0402}} & 14.48\\
\cmidrule(lr){2-14}
\multirow{2}{*}{Adap-Patch} 
& 5   & \underline{0.254} & \best{\underline{0.765}} & 44.03 & 0.0600 & 0.457 & 22.56 & \best{\underline{0.067}} & \underline{0.248} & 22.57 & \underline{0.0822} & \underline{0.588} & 26.72\\
& 0.3 & 0.0500 & 1.91 & 42.22 & \underline{0.0578} & \best{\underline{0.224}} & 21.47 & \underline{0.245} & \underline{0.084} & 23.21 & \underline{-0.0455} & \underline{0.106} & 14.28\\
\cmidrule(lr){2-14}
\multirow{2}{*}{Adap-Blend} 
& 5   & \underline{0.231} & \underline{1.15} & 41.84 & \best{0.0382} & 0.693 & 26.82 & 0.213 & 0.717 & 23.48 & 0.0630 & 1.26 & 22.74\\
& 0.3 & 0.149 & 2.10 & 45.98 & 0.191 & 1.28 & 34.52 & 0.311 & 0.996 & 44.38 & \best{\underline{-0.0657}} & \underline{0.965} & 18.05\\
\cmidrule(lr){2-14}
\multirow{2}{*}{DFST} 
& 5   & \worst{0.519} & 2.26 & 82.34 & 0.509 & 1.34 & 27.29 & 0.485 & 1.707 & 31.22 & \worst{0.641} & 2.20 & 127.10\\
& 0.3 & 0.339 & 2.63 & \worst{103.91} & \worst{0.730} & 1.93 & \worst{53.44} & \worst{0.63} & 1.74 & 56.63 & 0.261 & 2.15 & 54.43\\
\cmidrule(lr){2-14}
\multirow{2}{*}{Narcissus} 
& 5/0.7/0.4/5$^*$ & 0.491 & 2.23 & 50.21 & 0.0743 & 0.945 & 22.66 & 0.314 & 1.977 & \worst{60.64} & 0.0431 & 1.34 & 20.00\\
& 0.3 & -0.0070 & 1.90 & 25.68 & \underline{0.0620} & \underline{0.852} & 19.16 & 0.302 & 1.703 & 27.96 & \underline{-0.0164} & \underline{0.883} & 14.90\\
\cmidrule(lr){2-14}
\multirow{2}{*}{Grond} 
& 5/0.7/0.4/5$^*$ & 0.435 & 1.82 & 27.77 & \underline{0.233} & \underline{0.861} & 22.99 & 0.327 & 1.122 & 47.32 & 0.0308 & 1.05 & 22.79\\
& 0.3 & \best{-0.101} & 1.65 & \best{6.14} & \underline{0.208} & \underline{0.786} & 22.91 & 0.355 & 1.071 & 45.68 & \underline{0.0546} & \underline{0.286} & 14.83\\
\cmidrule(lr){2-14}
DFBA & - & - & \worst{15.2} & 16.56 & - & \worst{18.0} & 22.05 & - & \worst{10.74} & 39.45 & - & \worst{4.64} & \best{14.23}\\
\bottomrule
\end{tabular}
\end{table*}




\renewcommand{\arraystretch}{0.9}
\begin{table*}[t]
\centering
\caption{Parameter-space stealthiness of backdoored ResNet18 models trained on our three chosen datasets. The two metrics used to evaluate each model are the upper bound on the channel Lipschitz constant (UCLC) and trigger-activated change (TAC), both of which have the ideal value 0. For each metric and dataset, the \best{best} and \worst{worst} results are highlighted. Results that may be affected by the low ASR of the corresponding models (see \autoref{tab:attack-performance-4datasets}) are \underline{underlined}. *The poisoning rates vary per dataset.}
\label{tab:uclc-tac}
\begin{tabular}{l c c c c c c c c c}
\toprule
\multirow{2}{*}{Model} & \multirow{2}{*}{PR (\%)} 
& \multicolumn{2}{c}{CIFAR-10} 
& \multicolumn{2}{c}{CIFAR-100} 
& \multicolumn{2}{c}{Tiny-ImageNet} 
& \multicolumn{2}{c}{Imagenette} \\
\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-10}
& & UCLC$\downarrow$ & TAC$\downarrow$ & UCLC$\downarrow$ & TAC$\downarrow$ & UCLC$\downarrow$ & TAC$\downarrow$ & UCLC$\downarrow$ & TAC$\downarrow$\\
\midrule
Benign & - & 6.09 & - & 4.92 & - & 4.19 & - & 5.31 & - \\
\cmidrule(lr){2-10}
\multirow{2}{*}{BadNets} 
& 5   & 6.59 & 3.90 & 4.64 & 7.32 & 4.52 & 21.34 & 6.22 & 15.3 \\
& 0.3 & 7.99 & 8.03 & 5.86 & 9.17 & 4.57 & 38.89 & 5.39 & 18.4 \\
\cmidrule(lr){2-10}
\multirow{2}{*}{Blend} 
& 5   & 6.49 & 3.05 & 4.73 & 6.46 & 4.54 & 23.87 & 4.99 & 6.24 \\
& 0.3 & 5.76 & 4.30 & 4.92 & 9.69 & 4.85 & 25.31 & 5.37 & 6.04 \\
\cmidrule(lr){2-10}
\multirow{2}{*}{WaNet} 
& 5   & 6.33 & 10.7 & 6.52 & 20.9 & 4.27 & 31.08 & 7.05 & 64.0 \\
& 2/0.3/0.3/0.3$^*$ & 7.68 & 14.3 & 6.39 & 11.2 & 4.02 & 30.13 & 6.49 & 2.55 \\
\cmidrule(lr){2-10}
\multirow{2}{*}{BppAttack} 
& 5   & 9.42 & 8.50 & 8.76 & 16.3 & 7.9 & 32.41 & 8.82 & 59.2 \\
& 2/0.3/0.3/0.3$^*$ & 7.38 & 7.48 & 7.21 & 10.0 & \best{\underline{3.95}} & 10.63 & \underline{5.19} & \best{\underline{0.394}} \\
\cmidrule(lr){2-10}
\multirow{2}{*}{Adap-Patch} 
& 5   & \underline{10.7} & \underline{6.44} & 5.35 & 6.83 & 4.14 & 14.88 & \underline{6.24} & \underline{11.5} \\
& 0.3 & 9.91 & 3.94 & \underline{6.06} & \best{\underline{1.45}} & 5.57 & \best{\underline{10.44}} & \underline{7.62} & \underline{1.42} \\
\cmidrule(lr){2-10}
\multirow{2}{*}{Adap-Blend} 
& 5   & \underline{5.60} & \best{\underline{2.14}} & 6.32 & 6.62 & 4.41 & 21.18 & 5.08 & 5.61 \\
& 0.3 & 7.70 & 4.58 & 5.51 & 12.4 & 4.14 & 20.54 & \underline{5.67} & \underline{4.71} \\
\cmidrule(lr){2-10}
\multirow{2}{*}{DFST} 
& 5   & 6.16 & 6.41 & 4.28 & 11.9 & 4.35 & 26.05 & 6.29 & 18.9 \\
& 0.3 & 6.37 & 11.8 & 5.69 & 15.4 & 5.12 & 30.0 & 4.61 & 10.8 \\
\cmidrule(lr){2-10}
\multirow{2}{*}{Narcissus} 
& 5/0.7/0.4/5$^*$ & 7.37 & 6.23 & 6.19 & 6.25 & 4.28 & 35.86 & 5.41 & 5.59 \\
& 0.3 & 6.88 & 2.15 & \underline{5.44} & \underline{3.78} & 4.33 & 27.24 & \underline{6.42} & \underline{4.64} \\
\cmidrule(lr){2-10}
\multirow{2}{*}{Grond} 
& 5/0.7/0.4/5$^*$ & 3.60 & 2.43 & \best{\underline{3.78}} & \underline{6.00} & 4.33 & 21.89 & \best{3.14} & 4.20 \\
& 0.3 & \best{3.18} & 2.30 & \underline{4.10} & \underline{4.32} & 4.33 & 23.79 & \underline{3.73} & \underline{2.19} \\
\cmidrule(lr){2-10}
DFBA & - & \worst{17.8} & \worst{413} & \worst{17.7} & \worst{413} & \worst{21.17} & \worst{959.33} & \worst{18.7} & \worst{959} \\
\bottomrule
\end{tabular}
\end{table*}



\renewcommand{\arraystretch}{0.91}
\begin{table*}[t]
\centering
\caption{Stealthiness evaluation of backdoored ResNet18 models trained on four datasets, with the two metrics proposed in this study: 
the Davies-Bouldin index (DBI) and TAC-UCLC product (TUP). For the former metric, 0 is the worst possible measurement, whereas it is the ideal value for the latter metric. For each metric and dataset, the \best{best} and \worst{worst} results are highlighted. Results that may be affected by the low ASR of the corresponding models (see \autoref{tab:attack-performance-4datasets}) are \underline{underlined}. *The poisoning rates vary per dataset.}
\label{tab:results_newmetric_resnet18}
\begin{tabular}{l c c c c c c c c c c c}
\toprule
\multirow{2}{*}{Model} & \multirow{2}{*}{PR (\%)} 
& \multicolumn{2}{c}{CIFAR-10} 
& \multicolumn{2}{c}{CIFAR-100} 
& \multicolumn{2}{c}{Tiny-ImageNet} 
& \multicolumn{2}{c}{Imagenette} \\
\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-10}
& & CDBI$\downarrow$ & TUP$\downarrow$ & CDBI$\downarrow$ & TUP$\downarrow$ & CDBI$\downarrow$ & TUP$\downarrow$ & CDBI$\downarrow$ & TUP$\downarrow$\\
\midrule

    \multirow{2}{*}{BadNets} & 5 & 0.574 & 16.2 & 0.424 & 27.7 & 0.646 & 10.227 & \worst{0.418} & 18.4 \\

    & 0.3 & 0.627 & \worst{23.1} & 0.534 & 29.6 & 0.624 & 3.895 & 0.871 & \worst{19.3} \\
    \cmidrule(lr){2-10}

    \multirow{2}{*}{Blend} & 5 & 0.738 & 3.68 & 0.620 & 10.2 & 0.53 & 3.885 & 3.07 & 3.30 \\

    & 0.3 & 0.796 & 3.94 & 0.911 & 10.8 & 0.576 & 3.407 & 2.20 & 2.77 \\
    \cmidrule(lr){2-10}

    \multirow{2}{*}{WaNet} & 5 & 0.641 & 9.30 & 0.409 & 25.4 & 0.523 & 7.078 & 0.571 & 8.85 \\

    & 2/0.3/0.3/0.3$^*$ & 0.644 & 8.56 & 1.54 & 22.1 & 1.377 & 3.657 & 0.809 & 3.84 \\
    \cmidrule(lr){2-10}

    \multirow{2}{*}{BppAttack} & 5 & 0.640 & 21.0 & 0.477 & 52.4 & 0.584 & \worst{34.275} & 0.518 & 13.9 \\

    & 2/0.3/0.3/0.3$^*$ & 0.519 & 10.9 & 0.436 & \worst{56.1} & \underline{0.637} & \underline{3.578} & \underline{0.854} & \underline{1.56} \\
    \cmidrule(lr){2-10}

    \multirow{2}{*}{Adap-Patch} & 5 & \underline{1.29} & \underline{8.38} & 1.19 & 13.4 & \best{\underline{1.841}} & \underline{3.522} & \underline{2.90} & \underline{5.72} \\

    & 0.3 & 3.42 & 10.2 & \underline{2.27} & \underline{9.77} & \underline{0.622} & \underline{3.495} & \underline{4.45} & \underline{2.35} \\
    \cmidrule(lr){2-10}

    \multirow{2}{*}{Adap-Blend} & 5 & \underline{1.66} & \underline{3.34} & 1.24 & 9.93 & 0.916 & 3.209 & 3.00 & 3.29 \\

    & 0.3 & 5.19 & 3.63 & 1.53 & 11.2 & 0.497 & 3.451 & \underline{12.3} & \underline{2.45} \\
    \cmidrule(lr){2-10}

    \multirow{2}{*}{DFST} & 5 & 0.650 & 3.70 & 0.475 & 8.91 & 0.475 & \best{3.063} & 0.476 & 3.81 \\

    & 0.3 & \worst{0.550} & 4.47 & \worst{0.260} & 11.1 & \worst{0.353} & 3.093 & 0.934 & 4.43 \\
    \cmidrule(lr){2-10}

    \multirow{2}{*}{Narcissus} & 5/0.7/0.4/5$^*$ & 0.767 & 2.15 & 3.47 & 8.75 & 1.107 & 3.192 & 4.27 & 2.64 \\

    & 0.3 & \best{5.92} & 2.13 & \best{\underline{4.34}} & \best{\underline{8.48}} & 1.434 & 3.25 & \underline{7.54} & \underline{2.13} \\
    \cmidrule(lr){2-10}

    \multirow{2}{*}{Grond} & 5/0.7/0.4/5$^*$ & 0.868 & 1.87 & \underline{1.95} & \underline{8.86} & 1.074 & 3.236 & \best{24.0} & 1.61 \\

    & 0.3 & 5.81 & \best{1.78} & \underline{1.53} & \underline{8.64} & 1.19 & 3.368 & \underline{12.4} & \best{\underline{1.05}} \\
    \cmidrule(lr){2-10}

    DFBA & - & - & 10.2 & - & 10.6 & - & 3.917 & - & 13.5 \\
\bottomrule
\end{tabular}
\end{table*}


